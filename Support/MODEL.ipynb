{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1cRT1yPCV71nzo5VKDC96-W4-kNB2DsaR","authorship_tag":"ABX9TyPHe/4jG5oK60/CqYdY14i2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JFo6c9Y7Z_QQ"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import models\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","import os\n","from torchvision import datasets, transforms\n","from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n","from PIL import Image"]},{"cell_type":"code","source":["num_classes = 2\n","learning_rate = 0.001\n","dropout_rate = 0.5\n","batch_size = 32\n","num_epochs = 25"],"metadata":{"id":"48c56pzGaG0H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ResNetIrisTumor(nn.Module):\n","    def __init__(self, num_classes, dropout_rate):\n","        super(ResNetIrisTumor, self).__init__()\n","        self.resnet = models.resnet18(pretrained=True)\n","        self.resnet.fc = nn.Sequential(\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(self.resnet.fc.in_features, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.resnet(x)"],"metadata":{"id":"zy4DKPnqaVwZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = ResNetIrisTumor(num_classes=num_classes, dropout_rate=dropout_rate)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQ9ifvUPaYxW","executionInfo":{"status":"ok","timestamp":1735964938387,"user_tz":-330,"elapsed":1049,"user":{"displayName":"Gaana Shree S","userId":"05810742237468259576"}},"outputId":"ee619c1f-dfa0-4746-b262-2ed64c5fa91b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 136MB/s]\n"]}]},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","    def __init__(self, folder_path, label, transform=None):\n","        self.folder_path = folder_path\n","        self.label = label\n","        self.transform = transform\n","        self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path)]\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.image_paths[idx]\n","        image = Image.open(img_path).convert('RGB')\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, self.label"],"metadata":{"id":"jCx1Wn6CcBdv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tumor_path = \"/content/drive/MyDrive/INFOSYS SPRINGBOARD/IRIS/YES\"\n","no_tumor_path = \"/content/drive/MyDrive/INFOSYS SPRINGBOARD/IRIS/NO\""],"metadata":{"id":"iYZVyijZajNT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tumor_dataset = CustomDataset(tumor_path, label=1, transform=transform)\n","no_tumor_dataset = CustomDataset(no_tumor_path, label=0, transform=transform)\n","combined_dataset = ConcatDataset([tumor_dataset, no_tumor_dataset])\n","train_size = int(0.8 * len(combined_dataset))\n","val_size = len(combined_dataset) - train_size\n","train_data, val_data = random_split(combined_dataset, [train_size, val_size])"],"metadata":{"id":"3z4TET7-bgLJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xmJKDsY5NmlI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n","num_epochs=10\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to('cpu'), labels.to('cpu')\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        _, predicted = outputs.max(1)\n","        total += labels.size(0)\n","        correct += predicted.eq(labels).sum().item()\n","\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    epoch_acc = 100. * correct / total\n","\n","    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n","\n","    model.eval()\n","    val_loss = 0.0\n","    val_correct = 0\n","    val_total = 0\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to('cpu'), labels.to('cpu')\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            val_loss += loss.item() * inputs.size(0)\n","            _, predicted = outputs.max(1)\n","            val_total += labels.size(0)\n","            val_correct += predicted.eq(labels).sum().item()\n","\n","    val_epoch_loss = val_loss / len(val_loader.dataset)\n","    val_epoch_acc = 100. * val_correct / val_total\n","    print(f'Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_acc:.2f}%')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hLiDxBaOaDFG","executionInfo":{"status":"ok","timestamp":1735966127109,"user_tz":-330,"elapsed":1178199,"user":{"displayName":"Gaana Shree S","userId":"05810742237468259576"}},"outputId":"896166b9-e473-4d06-a5a3-720d85d12de1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Loss: 0.3865, Accuracy: 83.51%\n","Validation Loss: 0.1499, Validation Accuracy: 93.62%\n","Epoch 2/10, Loss: 0.0867, Accuracy: 96.28%\n","Validation Loss: 0.9232, Validation Accuracy: 80.85%\n","Epoch 3/10, Loss: 0.0376, Accuracy: 97.87%\n","Validation Loss: 5.5579, Validation Accuracy: 65.96%\n","Epoch 4/10, Loss: 0.0512, Accuracy: 97.87%\n","Validation Loss: 0.1208, Validation Accuracy: 95.74%\n","Epoch 5/10, Loss: 0.0059, Accuracy: 100.00%\n","Validation Loss: 0.1230, Validation Accuracy: 95.74%\n","Epoch 6/10, Loss: 0.0047, Accuracy: 100.00%\n","Validation Loss: 0.0848, Validation Accuracy: 95.74%\n","Epoch 7/10, Loss: 0.0125, Accuracy: 99.47%\n","Validation Loss: 0.1772, Validation Accuracy: 93.62%\n","Epoch 8/10, Loss: 0.0019, Accuracy: 100.00%\n","Validation Loss: 0.1832, Validation Accuracy: 93.62%\n","Epoch 9/10, Loss: 0.0006, Accuracy: 100.00%\n","Validation Loss: 0.1858, Validation Accuracy: 93.62%\n","Epoch 10/10, Loss: 0.0003, Accuracy: 100.00%\n","Validation Loss: 0.1786, Validation Accuracy: 93.62%\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), '/content/drive/MyDrive/INFOSYS SPRINGBOARD/Resnet.pth')\n"],"metadata":{"id":"do3YK4ojhEkn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install onnx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2gxmGp1Yqzj3","executionInfo":{"status":"ok","timestamp":1735966549414,"user_tz":-330,"elapsed":7796,"user":{"displayName":"Gaana Shree S","userId":"05810742237468259576"}},"outputId":"4cf6cfac-eb9c-44ff-b3d8-899139dc9a25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting onnx\n","  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.25.5)\n","Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: onnx\n","Successfully installed onnx-1.17.0\n"]}]},{"cell_type":"code","source":["import torch\n","\n","dummy_input = torch.randn(1, 3, 224, 224)  # Adjust dimensions as needed\n","torch.onnx.export(model, dummy_input, '/content/drive/MyDrive/INFOSYS SPRINGBOARD/Resnet.onnx')\n"],"metadata":{"id":"x3QMN52Bqr38"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scripted_model = torch.jit.script(model)  # Or torch.jit.trace for tracing\n","scripted_model.save('/content/drive/MyDrive/INFOSYS SPRINGBOARD/Resnet.pt')\n"],"metadata":{"id":"YaNztd4arAS1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.quantization import quantize_dynamic\n","\n","# Apply dynamic quantization\n","quantized_model = quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8)\n","torch.save(quantized_model.state_dict(), '/content/drive/MyDrive/INFOSYS SPRINGBOARD/Resnet_quantized.pth')\n"],"metadata":{"id":"i5baJMbOrV0m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn.utils.prune as prune\n","\n","# Apply pruning to layers\n","# Changed model.fc to model.resnet.fc to access the fully connected layer\n","prune.random_unstructured(model.resnet.fc[1], name=\"weight\", amount=0.5)  # Example: prune 50% weights of the linear layer within the sequential\n","torch.save(model.state_dict(), '/content/drive/MyDrive/INFOSYS SPRINGBOARD/Resnet_pruned.pth')"],"metadata":{"id":"u9RG11VkrkG3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model.state_dict(), '/content/drive/MyDrive/INFOSYS SPRINGBOARD/Resnet_weights_only.pth')\n"],"metadata":{"id":"7FBXARLmsEEx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# For ONNX\n","torch.onnx.export(model, dummy_input, '/content/drive/MyDrive/INFOSYS SPRINGBOARD/Resnet_optimized.onnx')\n","\n","# For TorchScript\n","scripted_model = torch.jit.script(model)\n","scripted_model.save('/content/drive/MyDrive/INFOSYS SPRINGBOARD/Resnet_optimized.pt')\n"],"metadata":{"id":"LsinIg7Psdi_"},"execution_count":null,"outputs":[]}]}