{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JFo6c9Y7Z_QQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kis1bL2G3GvE",
        "outputId": "dc7ea144-ee1d-41e6-d147-c85b04353324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "48c56pzGaG0H"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "learning_rate = 0.001\n",
        "dropout_rate = 0.5\n",
        "batch_size = 32\n",
        "num_epochs = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zy4DKPnqaVwZ"
      },
      "outputs": [],
      "source": [
        "class ResNetIrisTumor(nn.Module):\n",
        "    def __init__(self, num_classes, dropout_rate):\n",
        "        super(ResNetIrisTumor, self).__init__()\n",
        "        self.resnet = models.resnet18(pretrained=True)\n",
        "        self.resnet.fc = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(self.resnet.fc.in_features, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ9ifvUPaYxW",
        "outputId": "a325c553-f1cb-49e8-828f-c55b8a52208d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 118MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = ResNetIrisTumor(num_classes=num_classes, dropout_rate=dropout_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jCx1Wn6CcBdv"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, folder_path, label, transform=None):\n",
        "        self.folder_path = folder_path\n",
        "        self.label = label\n",
        "        self.transform = transform\n",
        "        self.image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, self.label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iYZVyijZajNT"
      },
      "outputs": [],
      "source": [
        "tumor_path = \"/content/drive/MyDrive/iristumordataset/YES\"\n",
        "no_tumor_path = \"/content/drive/MyDrive/iristumordataset/NO\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3z4TET7-bgLJ"
      },
      "outputs": [],
      "source": [
        "tumor_dataset = CustomDataset(tumor_path, label=1, transform=transform)\n",
        "no_tumor_dataset = CustomDataset(no_tumor_path, label=0, transform=transform)\n",
        "combined_dataset = ConcatDataset([tumor_dataset, no_tumor_dataset])\n",
        "train_size = int(0.8 * len(combined_dataset))\n",
        "val_size = len(combined_dataset) - train_size\n",
        "train_data, val_data = random_split(combined_dataset, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLiDxBaOaDFG",
        "outputId": "b42ed110-e446-4e99-93e8-a2f22d26a759"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 0.0129, Accuracy: 99.15%\n",
            "Validation Loss: 0.1277, Validation Accuracy: 90.00%\n",
            "Epoch 2/10, Loss: 0.0023, Accuracy: 100.00%\n",
            "Validation Loss: 0.4454, Validation Accuracy: 93.33%\n",
            "Epoch 3/10, Loss: 0.0073, Accuracy: 100.00%\n",
            "Validation Loss: 0.4051, Validation Accuracy: 93.33%\n",
            "Epoch 4/10, Loss: 0.0030, Accuracy: 100.00%\n",
            "Validation Loss: 0.2752, Validation Accuracy: 93.33%\n",
            "Epoch 5/10, Loss: 0.0030, Accuracy: 100.00%\n",
            "Validation Loss: 0.1722, Validation Accuracy: 96.67%\n",
            "Epoch 6/10, Loss: 0.0024, Accuracy: 100.00%\n",
            "Validation Loss: 0.1605, Validation Accuracy: 96.67%\n",
            "Epoch 7/10, Loss: 0.0004, Accuracy: 100.00%\n",
            "Validation Loss: 0.1821, Validation Accuracy: 93.33%\n",
            "Epoch 8/10, Loss: 0.0002, Accuracy: 100.00%\n",
            "Validation Loss: 0.2149, Validation Accuracy: 90.00%\n",
            "Epoch 9/10, Loss: 0.0059, Accuracy: 100.00%\n",
            "Validation Loss: 0.2521, Validation Accuracy: 93.33%\n",
            "Epoch 10/10, Loss: 0.0002, Accuracy: 100.00%\n",
            "Validation Loss: 0.6532, Validation Accuracy: 86.67%\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "num_epochs=10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to('cpu'), labels.to('cpu')\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_acc = 100. * correct / total\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to('cpu'), labels.to('cpu')\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    val_epoch_loss = val_loss / len(val_loader.dataset)\n",
        "    val_epoch_acc = 100. * val_correct / val_total\n",
        "    print(f'Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_acc:.2f}%')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "do3YK4ojhEkn"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/iristumordataset/Resnet.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gxmGp1Yqzj3",
        "outputId": "ecb99753-450a-4b7f-e985-2aabfd2aca9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.25.5)\n",
            "Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "x3QMN52Bqr38"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "dummy_input = torch.randn(1, 3, 224, 224)  # Adjust dimensions as needed\n",
        "torch.onnx.export(model, dummy_input, '/content/drive/MyDrive/iristumordataset/Resnet.onnx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YaNztd4arAS1"
      },
      "outputs": [],
      "source": [
        "scripted_model = torch.jit.script(model)  # Or torch.jit.trace for tracing\n",
        "scripted_model.save('/content/drive/MyDrive/iristumordataset/Resnet.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "i5baJMbOrV0m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.quantization import quantize_dynamic\n",
        "\n",
        "# Apply dynamic quantization\n",
        "quantized_model = quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8)\n",
        "torch.save(quantized_model.state_dict(), '/content/drive/MyDrive/iristumordataset/Resnet_quantized.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "u9RG11VkrkG3"
      },
      "outputs": [],
      "source": [
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "# Apply pruning to layers\n",
        "# Changed model.fc to model.resnet.fc to access the fully connected layer\n",
        "prune.random_unstructured(model.resnet.fc[1], name=\"weight\", amount=0.5)  # Example: prune 50% weights of the linear layer within the sequential\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/iristumordataset/Resnet_pruned.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7FBXARLmsEEx"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/iristumordataset/Resnet_weights_only.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsinIg7Psdi_",
        "outputId": "845f8ca5-5a82-4831-85d1-38024a0e706c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ONNX model saved to /content/drive/MyDrive/iristumordataset/Resnet_optimized.onnx\n",
            "TorchScript model saved to /content/drive/MyDrive/iristumordataset/Resnet_optimized.pt\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "# Define and load the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)  # Adjust output layer for your dataset\n",
        "model = model.to(device)\n",
        "model.eval()  # Ensure the model is in evaluation mode for exporting\n",
        "\n",
        "# Dummy input for exporting (match your model's input size)\n",
        "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
        "\n",
        "# Export to ONNX\n",
        "onnx_path = '/content/drive/MyDrive/iristumordataset/Resnet_optimized.onnx'\n",
        "torch.onnx.export(model, dummy_input, onnx_path, opset_version=11, input_names=['input'], output_names=['output'])\n",
        "print(f\"ONNX model saved to {onnx_path}\")\n",
        "\n",
        "# Export to TorchScript\n",
        "scripted_model = torch.jit.script(model)\n",
        "scripted_path = '/content/drive/MyDrive/iristumordataset/Resnet_optimized.pt'\n",
        "scripted_model.save(scripted_path)\n",
        "print(f\"TorchScript model saved to {scripted_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3i7EbGK_QJs",
        "outputId": "fa1e9d53-85aa-4ce6-c0f5-21bc9aef786e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (1.18.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.41.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLe2V3pN_QM1",
        "outputId": "e09237f2-a785-42a0-cf14-08ccab0137e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "app.py has been saved!\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "\n",
        "# Load PyTorch model\n",
        "@st.cache_resource\n",
        "def load_torch_model(model_path):\n",
        "    model = torch.jit.load(model_path)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Load ONNX model\n",
        "@st.cache_resource\n",
        "def load_onnx_model(model_path):\n",
        "    session = ort.InferenceSession(model_path)\n",
        "    return session\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_image(image, target_size=(224, 224)):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(target_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    return transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Prediction function for PyTorch\n",
        "def predict_torch(image_tensor, model):\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "    return predicted.item()\n",
        "\n",
        "# Prediction function for ONNX\n",
        "def predict_onnx(image_tensor, session):\n",
        "    input_name = session.get_inputs()[0].name\n",
        "    output = session.run(None, {input_name: image_tensor.numpy()})\n",
        "    predicted = np.argmax(output[0], axis=1)\n",
        "    return predicted[0]\n",
        "\n",
        "# Streamlit UI\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    <style>\n",
        "    .main {\n",
        "        background-color: pink;\n",
        "        padding: 5rem;\n",
        "    }\n",
        "    .title {\n",
        "        text-align: center;\n",
        "        color: black;\n",
        "        font-size: 36px;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\", unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "st.title(\"Iris Tumor Classification\")\n",
        "\n",
        "# Customizing title style\n",
        "st.markdown('<h1 class=\"title\">Iris Tumor Classification</h1>', unsafe_allow_html=True)\n",
        "\n",
        "st.write(\"Upload an image of the iris to classify as tumor or no tumor.\")\n",
        "\n",
        "# Sidebar for model selection\n",
        "model_type = st.sidebar.selectbox(\"Choose a model\", [\"PyTorch\", \"ONNX\"])\n",
        "\n",
        "# Model paths\n",
        "torch_model_path = \"/content/drive/MyDrive/iristumordataset/Resnet.pt\"\n",
        "onnx_model_path = \"/content/drive/MyDrive/iristumordataset/Resnet.onnx\"\n",
        "\n",
        "# Load the selected model\n",
        "if model_type == \"PyTorch\":\n",
        "    model = load_torch_model(torch_model_path)\n",
        "else:\n",
        "    session = load_onnx_model(onnx_model_path)\n",
        "\n",
        "# File uploader\n",
        "uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "if uploaded_file:\n",
        "    # Display uploaded image\n",
        "    image = Image.open(uploaded_file).convert(\"RGB\")\n",
        "    st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "    # Preprocess the image\n",
        "    st.write(\"Processing the image...\")\n",
        "    image_tensor = preprocess_image(image)\n",
        "\n",
        "    # Make predictions\n",
        "    if model_type == \"PyTorch\":\n",
        "        prediction = predict_torch(image_tensor, model)\n",
        "    else:\n",
        "        # Convert Torch tensor to NumPy array for ONNX\n",
        "        prediction = predict_onnx(image_tensor, session)\n",
        "\n",
        "    # Display the prediction\n",
        "    if prediction == 1:\n",
        "        st.success(\"Prediction: Tumor Detected\")\n",
        "    else:\n",
        "        st.success(\"Prediction: No Tumor Detected\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k7J0DJO_bsL",
        "outputId": "5330403e-30f0-49ff-ba1c-af92ddf5488e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.138.101.74:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMe3loT9_bvm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
